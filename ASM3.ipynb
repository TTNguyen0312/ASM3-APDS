{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8HB8p7IwlQI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OPYh8jzuLYj",
        "outputId": "bd9c655d-3f77-4c8b-8b19-b2e19be8c2df"
      },
      "outputs": [],
      "source": [
        "# The following code is only for Google Colab.\n",
        "# If you are running this notebook locally, you should not run this cell.\n",
        "\n",
        "# %pip install google-colab\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qlZMxqeCyc3X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from nltk.tokenize import RegexpTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZZ_6YGDxnHE",
        "outputId": "614a8dc0-5de1-4332-a473-5704c57ccb4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: d:\\RMIT\\SEM B - 2025\\Data\\ASM3\\ASM3-APDS\n"
          ]
        }
      ],
      "source": [
        "current_directory = Path(__file__).parent if '__file__' in locals() else Path.cwd()\n",
        "print(f\"Current directory: {current_directory}\")\n",
        "with zipfile.ZipFile(f\"{current_directory}/data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "hxVFejQ8yPk1",
        "outputId": "3f098bad-698e-424c-b140-01663565e59d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1080</td>\n",
              "      <td>49</td>\n",
              "      <td>Not for the very petite</td>\n",
              "      <td>I love tracy reese dresses, but this one is no...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>858</td>\n",
              "      <td>39</td>\n",
              "      <td>Cagrcoal shimmer fun</td>\n",
              "      <td>I aded this in my basket at hte last mintue to...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19657</th>\n",
              "      <td>1104</td>\n",
              "      <td>34</td>\n",
              "      <td>Great dress for many occasions</td>\n",
              "      <td>I was very happy to snag this dress at such a ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19658</th>\n",
              "      <td>862</td>\n",
              "      <td>48</td>\n",
              "      <td>Wish it was made of cotton</td>\n",
              "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19659</th>\n",
              "      <td>1104</td>\n",
              "      <td>31</td>\n",
              "      <td>Cute, but see through</td>\n",
              "      <td>This fit well, but the top was very see throug...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19660</th>\n",
              "      <td>1084</td>\n",
              "      <td>28</td>\n",
              "      <td>Very cute dress, perfect for summer parties an...</td>\n",
              "      <td>I bought this dress for a wedding i have this ...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19661</th>\n",
              "      <td>1104</td>\n",
              "      <td>52</td>\n",
              "      <td>Please make more like this one!</td>\n",
              "      <td>This dress in a lovely platinum is feminine an...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19662 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Clothing ID  Age                                              Title  \\\n",
              "0             1077   60                            Some major design flaws   \n",
              "1             1049   50                                   My favorite buy!   \n",
              "2              847   47                                   Flattering shirt   \n",
              "3             1080   49                            Not for the very petite   \n",
              "4              858   39                               Cagrcoal shimmer fun   \n",
              "...            ...  ...                                                ...   \n",
              "19657         1104   34                     Great dress for many occasions   \n",
              "19658          862   48                         Wish it was made of cotton   \n",
              "19659         1104   31                              Cute, but see through   \n",
              "19660         1084   28  Very cute dress, perfect for summer parties an...   \n",
              "19661         1104   52                    Please make more like this one!   \n",
              "\n",
              "                                             Review Text  Rating  \\\n",
              "0      I had such high hopes for this dress and reall...       3   \n",
              "1      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
              "2      This shirt is very flattering to all due to th...       5   \n",
              "3      I love tracy reese dresses, but this one is no...       2   \n",
              "4      I aded this in my basket at hte last mintue to...       5   \n",
              "...                                                  ...     ...   \n",
              "19657  I was very happy to snag this dress at such a ...       5   \n",
              "19658  It reminds me of maternity clothes. soft, stre...       3   \n",
              "19659  This fit well, but the top was very see throug...       3   \n",
              "19660  I bought this dress for a wedding i have this ...       3   \n",
              "19661  This dress in a lovely platinum is feminine an...       5   \n",
              "\n",
              "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
              "0                    0                        0         General   \n",
              "1                    1                        0  General Petite   \n",
              "2                    1                        6         General   \n",
              "3                    0                        4         General   \n",
              "4                    1                        1  General Petite   \n",
              "...                ...                      ...             ...   \n",
              "19657                1                        0  General Petite   \n",
              "19658                1                        0  General Petite   \n",
              "19659                0                        1  General Petite   \n",
              "19660                1                        2         General   \n",
              "19661                1                       22  General Petite   \n",
              "\n",
              "      Department Name Class Name  \n",
              "0             Dresses    Dresses  \n",
              "1             Bottoms      Pants  \n",
              "2                Tops    Blouses  \n",
              "3             Dresses    Dresses  \n",
              "4                Tops      Knits  \n",
              "...               ...        ...  \n",
              "19657         Dresses    Dresses  \n",
              "19658            Tops      Knits  \n",
              "19659         Dresses    Dresses  \n",
              "19660         Dresses    Dresses  \n",
              "19661         Dresses    Dresses  \n",
              "\n",
              "[19662 rows x 10 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/assignment3.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['had', 'such', 'high', 'hopes', 'for', 'this', 'dress', 'and', 'really', 'wanted', 'it', 'to', 'work', 'for', 'me', 'initially', 'ordered', 'the', 'petite', 'small', 'my', 'usual', 'size', 'but', 'found', 'this', 'to', 'be', 'outrageously', 'small', 'so', 'small', 'in', 'fact', 'that', 'could', 'not', 'zip', 'it', 'up', 'reordered', 'it', 'in', 'petite', 'medium', 'which', 'was', 'just', 'ok', 'overall', 'the', 'top', 'half', 'was', 'comfortable', 'and', 'fit', 'nicely', 'but', 'the', 'bottom', 'half', 'had', 'very', 'tight', 'under', 'layer', 'and', 'several', 'somewhat', 'cheap', 'net', 'over', 'layers', 'imo', 'major', 'design', 'flaw', 'was', 'the', 'net', 'over', 'layer', 'sewn', 'directly', 'into', 'the', 'zipper', 'it'], ['love', 'love', 'love', 'this', 'jumpsuit', \"it's\", 'fun', 'flirty', 'and', 'fabulous', 'every', 'time', 'wear', 'it', 'get', 'nothing', 'but', 'great', 'compliments'], ['this', 'shirt', 'is', 'very', 'flattering', 'to', 'all', 'due', 'to', 'the', 'adjustable', 'front', 'tie', 'it', 'is', 'the', 'perfect', 'length', 'to', 'wear', 'with', 'leggings', 'and', 'it', 'is', 'sleeveless', 'so', 'it', 'pairs', 'well', 'with', 'any', 'cardigan', 'love', 'this', 'shirt']]\n"
          ]
        }
      ],
      "source": [
        "# 2/3/4. Tokenizing clothing review\n",
        "\n",
        "# define tokenizer\n",
        "tokenizer = RegexpTokenizer(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\")\n",
        "\n",
        "# Tokenize the review text + lowercasing and removing words with length < 2\n",
        "df[\"tokens\"] = (\n",
        "    df[\"Review Text\"]\n",
        "      .fillna(\"\") # replace NaN with empty string\n",
        "      .astype(str)\n",
        "      .apply(lambda text: [token.lower() for token in tokenizer.tokenize(text) if len(token) > 1])\n",
        ")\n",
        "\n",
        "# quick spot-checks (delete when done)\n",
        "print(df[\"tokens\"].head(3).tolist())\n",
        "assert isinstance(df[\"tokens\"].iloc[0], list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Q5] Loaded 570 stopwords from data\\stopwords_en.txt\n",
            "                                              tokens\n",
            "0  [high, hopes, dress, wanted, work, initially, ...\n",
            "1  [love, love, love, jumpsuit, fun, flirty, fabu...\n",
            "df['tokens'] ready for Step 6 & 7.\n"
          ]
        }
      ],
      "source": [
        "# 5. Remove stopwords using the provided stop words list (i.e., stopwords_en.txt). It is located inside the same downloaded folder. \n",
        "# Find file stopwords in data\n",
        "stop_candidates = [Path(\"stopwords_en.txt\"), Path(\"data/stopwords_en.txt\")]\n",
        "stop_path = next((p for p in stop_candidates if p.exists()), None)\n",
        "assert stop_path is not None, \"stopwords_en.txt not found. Please put it in project root or inside data/.\"\n",
        "\n",
        "# Load stopwords\n",
        "with open(stop_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    STOPWORDS = {line.strip() for line in f if line.strip()}\n",
        "\n",
        "print(f\"[Q5] Loaded {len(STOPWORDS)} stopwords from {stop_path}\")\n",
        "\n",
        "# Remove stopwords (Compare lowercase)\n",
        "def remove_stopwords(tokens, stopset):\n",
        "    return [t for t in tokens if t.lower() not in stopset]\n",
        "\n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda xs: remove_stopwords(xs, STOPWORDS))\n",
        "\n",
        "# Print to check\n",
        "print(df[[\"tokens\"]].head(2))\n",
        "print(\"df['tokens'] ready for Step 6 & 7.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dress          9334\n",
              "size           7860\n",
              "love           7722\n",
              "fit            6582\n",
              "top            6542\n",
              "               ... \n",
              "theatre           2\n",
              "flatttering       2\n",
              "cutie             2\n",
              "exacerbated       2\n",
              "thoughtful        2\n",
              "Name: count, Length: 7549, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. Remove the word that appears only once in the document collection, based on term frequency.\n",
        "term_freq = pd.Series(np.concatenate(df[\"tokens\"].values)).value_counts()\n",
        " \n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda tokens: [token for token in tokens if term_freq[token] > 1])\n",
        "\n",
        "# Double check\n",
        "term_freq = pd.Series(np.concatenate(df[\"tokens\"].values)).value_counts()\n",
        "term_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fits          2541\n",
              "beautiful     2491\n",
              "large         2485\n",
              "material      2438\n",
              "length        2366\n",
              "              ... \n",
              "suspected        2\n",
              "rhinestone       2\n",
              "names            2\n",
              "themed           2\n",
              "film             2\n",
              "Name: count, Length: 7529, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# 7. Remove the top 20 most frequent words based on document frequency. \n",
        "top_20_words = term_freq.nlargest(20).index\n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda tokens: [token for token in tokens if token not in top_20_words])\n",
        "\n",
        "# Double check\n",
        "term_freq = pd.Series(np.concatenate(df[\"tokens\"].values)).value_counts()\n",
        "term_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        [high, hopes, wanted, work, initially, petite,...\n",
              "1        [jumpsuit, fun, flirty, fabulous, time, compli...\n",
              "2        [shirt, due, adjustable, front, tie, length, l...\n",
              "3        [tracy, reese, dresses, petite, feet, tall, br...\n",
              "4        [basket, hte, person, store, pick, teh, pale, ...\n",
              "                               ...                        \n",
              "19657         [happy, snag, price, easy, slip, cut, combo]\n",
              "19658    [reminds, maternity, clothes, stretchy, shiny,...\n",
              "19659                 [worked, glad, store, order, online]\n",
              "19660    [wedding, summer, medium, fits, waist, perfect...\n",
              "19661    [lovely, feminine, fits, perfectly, easy, comf...\n",
              "Name: tokens, Length: 19662, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"tokens\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(f\"processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Build a vocabulary of the cleaned/processed reviews, and save it in a txt file (please refer to the\n",
        "# Required Output section);\n",
        "vocabulary = set(np.concatenate(df[\"tokens\"].values))\n",
        "vocabulary = sorted(vocabulary)\n",
        "vocab_dict = {word: i for i, word in enumerate(vocabulary)}\n",
        "with open(\"vocabulary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for word, index in vocab_dict.items():\n",
        "        f.write(f\"{word}:{index}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2: Generating Feature Representations for Clothing Reviews\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Bag-of-words model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Vocab] Loaded 7529 words from vocabulary.txt\n"
          ]
        }
      ],
      "source": [
        "# === Task 2: Bag-of-Words ===\n",
        "from pathlib import Path\n",
        "\n",
        "#  — Load vocabulary (from Task 1) —\n",
        "VOCAB_PATHS = [\n",
        "    Path(\"vocabulary.txt\"),          \n",
        "]\n",
        "VOCAB_PATH = next((p for p in VOCAB_PATHS if p.exists()), None)\n",
        "assert VOCAB_PATH is not None, \"Không tìm thấy vocab (vocab.txt / vocabulary.txt).\"\n",
        "\n",
        "word2idx = {}\n",
        "with open(VOCAB_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        s = line.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        w, sidx = s.rsplit(\":\", 1)\n",
        "        word2idx[w] = int(sidx)\n",
        "\n",
        "print(f\"[Vocab] Loaded {len(word2idx)} words from {VOCAB_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BOW] Using tokens from column: tokens\n",
            "[['high', 'hopes', 'wanted', 'work', 'initially', 'petite', 'usual', 'found', 'outrageously', 'fact', 'zip', 'reordered', 'petite', 'medium', 'half', 'nicely', 'bottom', 'half', 'tight', 'layer', 'cheap', 'net', 'layers', 'imo', 'major', 'design', 'flaw', 'net', 'layer', 'sewn', 'directly', 'zipper'], ['jumpsuit', 'fun', 'flirty', 'fabulous', 'time', 'compliments']]\n"
          ]
        }
      ],
      "source": [
        "# === Task 2: Choose clean ===\n",
        "# Check df is available or not\n",
        "if \"df\" not in globals():\n",
        "    if Path(\"processed.csv\").exists():\n",
        "        df = pd.read_csv(\"processed.csv\")\n",
        "    else:\n",
        "        raise RuntimeError(\"df is not defined. Run task1 cell first.\")\n",
        "\n",
        "# Set name tokens\n",
        "CANDIDATE_TOKEN_COLS = [\"tokens\"]\n",
        "SOURCE_COL = next((c for c in CANDIDATE_TOKEN_COLS if c in df.columns), None)\n",
        "assert SOURCE_COL is not None, f\"Không thấy cột tokens. Kỳ vọng một trong: {CANDIDATE_TOKEN_COLS}\"\n",
        "\n",
        "# make sure tokens are a list\n",
        "def _ensure_list(x):\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if isinstance(x, str):\n",
        "        try:\n",
        "            import ast\n",
        "            val = ast.literal_eval(x)\n",
        "            return val if isinstance(val, list) else [x]\n",
        "        except Exception:\n",
        "            return x.split() \n",
        "    return []\n",
        "\n",
        "df[SOURCE_COL] = df[SOURCE_COL].apply(_ensure_list)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "print(f\"[BOW] Using tokens from column: {SOURCE_COL}\")\n",
        "print(df[SOURCE_COL].head(2).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BOW] Wrote 19662 lines to D:\\RMIT\\SEM B - 2025\\Data\\ASM3\\ASM3-APDS\\count_vectors.txt\n",
            "#0,686:1,1027:1,1715:1,1791:1,2288:1,2481:1,2602:1,2892:2,3010:1,3087:1,3193:1,3258:1,3549:2,3552:1,3832:1,3934:1,4224:2,4234:1,4427:1,4639:2,5260:1,5668:1,6726:1,7092:1,7207:1,7406:1,7520:1,7522:1\n",
            "#1,1286:1,2283:1,2502:1,2667:1,3403:1,6739:1\n",
            "#2,86:1,924:1,1987:1,2646:1,3584:1,3595:1,4506:1,5736:2,5924:1,6716:1\n"
          ]
        }
      ],
      "source": [
        "# === Task 2: Generate sparse Count Vectors -> count_vectors.txt ===\n",
        "from collections import Counter\n",
        "\n",
        "out_path = Path(\"count_vectors.txt\")\n",
        "\n",
        "def tokens_to_sparse_counts(tokens, word2idx):\n",
        "    tokens = [t.lower() for t in tokens if isinstance(t, str)]\n",
        "    ctr = Counter()\n",
        "    for t in tokens:\n",
        "        idx = word2idx.get(t)\n",
        "        if idx is not None:\n",
        "            ctr[idx] += 1\n",
        "    if not ctr:\n",
        "        return \"\"  \n",
        "    parts = [f\"{i}:{ctr[i]}\" for i in sorted(ctr)]\n",
        "    return \",\".join(parts)\n",
        "\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for i, toks in enumerate(df[SOURCE_COL]):\n",
        "        sparse = tokens_to_sparse_counts(toks, word2idx)\n",
        "        fout.write(f\"#{i},{sparse}\\n\")\n",
        "\n",
        "print(f\"[BOW] Wrote {len(df)} lines to {out_path.resolve()}\")\n",
        "# Print to check some first rows\n",
        "with open(out_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for _ in range(3):\n",
        "        print(f.readline().rstrip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Check Sanity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Check] Vocab indices contiguous 0..N-1: True\n",
            "[Check] All indices valid and counts > 0: True\n"
          ]
        }
      ],
      "source": [
        "# === Optional sanity checks ===\n",
        "# 1) vocab index must be from 0..N-1\n",
        "N = len(word2idx)\n",
        "ok_index_set = set(range(N)) == set(word2idx.values())\n",
        "print(\"[Check] Vocab indices contiguous 0..N-1:\", ok_index_set)\n",
        "\n",
        "# 2) Every index in count_vectors.txt < N\n",
        "bad = False\n",
        "with open(\"count_vectors.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\",\", 1)\n",
        "        if len(parts) == 2 and parts[1]:\n",
        "            for kv in parts[1].split(\",\"):\n",
        "                i, c = kv.split(\":\")\n",
        "                if int(i) >= N or int(c) <= 0:\n",
        "                    bad = True; break\n",
        "        if bad: break\n",
        "print(\"[Check] All indices valid and counts > 0:\", not bad)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
