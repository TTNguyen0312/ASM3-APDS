{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8HB8p7IwlQI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OPYh8jzuLYj",
        "outputId": "bd9c655d-3f77-4c8b-8b19-b2e19be8c2df"
      },
      "outputs": [],
      "source": [
        "# The following code is only for Google Colab.\n",
        "# If you are running this notebook locally, you should not run this cell.\n",
        "\n",
        "# %pip install google-colab\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "qlZMxqeCyc3X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/vongoc/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/vongoc/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/vongoc/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /Users/vongoc/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/vongoc/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /Users/vongoc/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZZ_6YGDxnHE",
        "outputId": "614a8dc0-5de1-4332-a473-5704c57ccb4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /Users/vongoc/Documents/GitHub/ASM3-APDS\n"
          ]
        }
      ],
      "source": [
        "current_directory = Path(__file__).parent if '__file__' in locals() else Path.cwd()\n",
        "print(f\"Current directory: {current_directory}\")\n",
        "with zipfile.ZipFile(f\"{current_directory}/data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "hxVFejQ8yPk1",
        "outputId": "3f098bad-698e-424c-b140-01663565e59d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1080</td>\n",
              "      <td>49</td>\n",
              "      <td>Not for the very petite</td>\n",
              "      <td>I love tracy reese dresses, but this one is no...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>858</td>\n",
              "      <td>39</td>\n",
              "      <td>Cagrcoal shimmer fun</td>\n",
              "      <td>I aded this in my basket at hte last mintue to...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19657</th>\n",
              "      <td>1104</td>\n",
              "      <td>34</td>\n",
              "      <td>Great dress for many occasions</td>\n",
              "      <td>I was very happy to snag this dress at such a ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19658</th>\n",
              "      <td>862</td>\n",
              "      <td>48</td>\n",
              "      <td>Wish it was made of cotton</td>\n",
              "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19659</th>\n",
              "      <td>1104</td>\n",
              "      <td>31</td>\n",
              "      <td>Cute, but see through</td>\n",
              "      <td>This fit well, but the top was very see throug...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19660</th>\n",
              "      <td>1084</td>\n",
              "      <td>28</td>\n",
              "      <td>Very cute dress, perfect for summer parties an...</td>\n",
              "      <td>I bought this dress for a wedding i have this ...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19661</th>\n",
              "      <td>1104</td>\n",
              "      <td>52</td>\n",
              "      <td>Please make more like this one!</td>\n",
              "      <td>This dress in a lovely platinum is feminine an...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19662 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Clothing ID  Age                                              Title  \\\n",
              "0             1077   60                            Some major design flaws   \n",
              "1             1049   50                                   My favorite buy!   \n",
              "2              847   47                                   Flattering shirt   \n",
              "3             1080   49                            Not for the very petite   \n",
              "4              858   39                               Cagrcoal shimmer fun   \n",
              "...            ...  ...                                                ...   \n",
              "19657         1104   34                     Great dress for many occasions   \n",
              "19658          862   48                         Wish it was made of cotton   \n",
              "19659         1104   31                              Cute, but see through   \n",
              "19660         1084   28  Very cute dress, perfect for summer parties an...   \n",
              "19661         1104   52                    Please make more like this one!   \n",
              "\n",
              "                                             Review Text  Rating  \\\n",
              "0      I had such high hopes for this dress and reall...       3   \n",
              "1      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
              "2      This shirt is very flattering to all due to th...       5   \n",
              "3      I love tracy reese dresses, but this one is no...       2   \n",
              "4      I aded this in my basket at hte last mintue to...       5   \n",
              "...                                                  ...     ...   \n",
              "19657  I was very happy to snag this dress at such a ...       5   \n",
              "19658  It reminds me of maternity clothes. soft, stre...       3   \n",
              "19659  This fit well, but the top was very see throug...       3   \n",
              "19660  I bought this dress for a wedding i have this ...       3   \n",
              "19661  This dress in a lovely platinum is feminine an...       5   \n",
              "\n",
              "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
              "0                    0                        0         General   \n",
              "1                    1                        0  General Petite   \n",
              "2                    1                        6         General   \n",
              "3                    0                        4         General   \n",
              "4                    1                        1  General Petite   \n",
              "...                ...                      ...             ...   \n",
              "19657                1                        0  General Petite   \n",
              "19658                1                        0  General Petite   \n",
              "19659                0                        1  General Petite   \n",
              "19660                1                        2         General   \n",
              "19661                1                       22  General Petite   \n",
              "\n",
              "      Department Name Class Name  \n",
              "0             Dresses    Dresses  \n",
              "1             Bottoms      Pants  \n",
              "2                Tops    Blouses  \n",
              "3             Dresses    Dresses  \n",
              "4                Tops      Knits  \n",
              "...               ...        ...  \n",
              "19657         Dresses    Dresses  \n",
              "19658            Tops      Knits  \n",
              "19659         Dresses    Dresses  \n",
              "19660         Dresses    Dresses  \n",
              "19661         Dresses    Dresses  \n",
              "\n",
              "[19662 rows x 10 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/assignment3.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['had', 'such', 'high', 'hopes', 'for', 'this', 'dress', 'and', 'really', 'wanted', 'it', 'to', 'work', 'for', 'me', 'initially', 'ordered', 'the', 'petite', 'small', 'my', 'usual', 'size', 'but', 'found', 'this', 'to', 'be', 'outrageously', 'small', 'so', 'small', 'in', 'fact', 'that', 'could', 'not', 'zip', 'it', 'up', 'reordered', 'it', 'in', 'petite', 'medium', 'which', 'was', 'just', 'ok', 'overall', 'the', 'top', 'half', 'was', 'comfortable', 'and', 'fit', 'nicely', 'but', 'the', 'bottom', 'half', 'had', 'very', 'tight', 'under', 'layer', 'and', 'several', 'somewhat', 'cheap', 'net', 'over', 'layers', 'imo', 'major', 'design', 'flaw', 'was', 'the', 'net', 'over', 'layer', 'sewn', 'directly', 'into', 'the', 'zipper', 'it'], ['love', 'love', 'love', 'this', 'jumpsuit', \"it's\", 'fun', 'flirty', 'and', 'fabulous', 'every', 'time', 'wear', 'it', 'get', 'nothing', 'but', 'great', 'compliments'], ['this', 'shirt', 'is', 'very', 'flattering', 'to', 'all', 'due', 'to', 'the', 'adjustable', 'front', 'tie', 'it', 'is', 'the', 'perfect', 'length', 'to', 'wear', 'with', 'leggings', 'and', 'it', 'is', 'sleeveless', 'so', 'it', 'pairs', 'well', 'with', 'any', 'cardigan', 'love', 'this', 'shirt']]\n"
          ]
        }
      ],
      "source": [
        "# 2/3/4. Tokenizing clothing review\n",
        "\n",
        "# define tokenizer\n",
        "tokenizer = RegexpTokenizer(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\")\n",
        "\n",
        "# Tokenize the review text + lowercasing and removing words with length < 2\n",
        "df[\"tokens\"] = (\n",
        "    df[\"Review Text\"]\n",
        "      .fillna(\"\") # replace NaN with empty string\n",
        "      .astype(str)\n",
        "      .apply(lambda text: [token.lower() for token in tokenizer.tokenize(text) if len(token) > 1])\n",
        ")\n",
        "\n",
        "# quick spot-checks (delete when done)\n",
        "print(df[\"tokens\"].head(3).tolist())\n",
        "assert isinstance(df[\"tokens\"].iloc[0], list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Q5] Loaded 570 stopwords from data/stopwords_en.txt\n",
            "                                              tokens\n",
            "0  [high, hopes, dress, wanted, work, initially, ...\n",
            "1  [love, love, love, jumpsuit, fun, flirty, fabu...\n",
            "df['tokens'] ready for Step 6 & 7.\n"
          ]
        }
      ],
      "source": [
        "# 5. Remove stopwords using the provided stop words list (i.e., stopwords_en.txt). It is located inside the same downloaded folder. \n",
        "# Find file stopwords in data\n",
        "stop_candidates = [Path(\"stopwords_en.txt\"), Path(\"data/stopwords_en.txt\")]\n",
        "stop_path = next((p for p in stop_candidates if p.exists()), None)\n",
        "assert stop_path is not None, \"stopwords_en.txt not found. Please put it in project root or inside data/.\"\n",
        "\n",
        "# Load stopwords\n",
        "with open(stop_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    STOPWORDS = {line.strip() for line in f if line.strip()}\n",
        "\n",
        "print(f\"[Q5] Loaded {len(STOPWORDS)} stopwords from {stop_path}\")\n",
        "\n",
        "# Remove stopwords (Compare lowercase)\n",
        "def remove_stopwords(tokens, stopset):\n",
        "    return [t for t in tokens if t.lower() not in stopset]\n",
        "\n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda xs: remove_stopwords(xs, STOPWORDS))\n",
        "\n",
        "# Print to check\n",
        "print(df[[\"tokens\"]].head(2))\n",
        "print(\"df['tokens'] ready for Step 6 & 7.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dress          9334\n",
              "size           7860\n",
              "love           7722\n",
              "fit            6582\n",
              "top            6542\n",
              "               ... \n",
              "upsize            2\n",
              "relaxed-fit       2\n",
              "undressed         2\n",
              "connected         2\n",
              "crosswrap         2\n",
              "Name: count, Length: 7549, dtype: int64"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. Remove the word that appears only once in the document collection, based on term frequency.\n",
        "term_freq = pd.Series(np.concatenate(df[\"tokens\"].values)).value_counts()\n",
        " \n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda tokens: [token for token in tokens if term_freq[token] > 1])\n",
        "\n",
        "# Double check\n",
        "term_freq = pd.Series(np.concatenate(df[\"tokens\"].values)).value_counts()\n",
        "term_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fits           2541\n",
              "beautiful      2491\n",
              "large          2485\n",
              "material       2438\n",
              "length         2366\n",
              "               ... \n",
              "upsize            2\n",
              "relaxed-fit       2\n",
              "undressed         2\n",
              "connected         2\n",
              "crosswrap         2\n",
              "Name: count, Length: 7529, dtype: int64"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# 7. Remove the top 20 most frequent words based on document frequency. \n",
        "top_20_words = term_freq.nlargest(20).index\n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda tokens: [token for token in tokens if token not in top_20_words])\n",
        "\n",
        "# Double check\n",
        "term_freq = pd.Series(np.concatenate(df[\"tokens\"].values)).value_counts()\n",
        "term_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "df[\"stemmed_tokens\"] = df[\"tokens\"].apply(lambda tokens: [stemmer.stem(t) for t in tokens])\n",
        "\n",
        "# -------------------------------\n",
        "# POS-aware Lemmatization\n",
        "# -------------------------------\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Map POS tags to WordNet\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # default to noun\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    return [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
        "\n",
        "df[\"lemmatized_tokens\"] = df[\"tokens\"].apply(lemmatize_tokens)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               tokens  \\\n",
            "0   [high, hopes, wanted, work, initially, petite,...   \n",
            "1   [jumpsuit, fun, flirty, fabulous, time, compli...   \n",
            "2   [shirt, due, adjustable, front, tie, length, l...   \n",
            "3   [tracy, reese, dresses, petite, feet, tall, br...   \n",
            "4   [basket, hte, person, store, pick, teh, pale, ...   \n",
            "5   [carbon, store, pick, ton, stuff, pair, skirts...   \n",
            "6   [xs, runs, snug, bust, feminine, usual, retail...   \n",
            "7   [lbs, petite, make, length, long, typically, x...   \n",
            "8   [runs, esp, zipper, area, runs, sp, typically,...   \n",
            "9   [find, reviews, written, savvy, shoppers, past...   \n",
            "10  [black, xs, larkspur, midi, bother, lining, sk...   \n",
            "11  [choice, holiday, gatherings, length, knee, co...   \n",
            "12  [package, wanted, badly, put, hour-glass, figu...   \n",
            "13  [material, leg, opening, large, length, hits, ...   \n",
            "14  [chance, blouse, glad, crazy, blouse, photogra...   \n",
            "15  [super, cozy, coat, work, cold, dry, days, goo...   \n",
            "16  [feel, tulle, year's, eve, chested, form, fitt...   \n",
            "17  [product, petite, petite, regular, long, tailo...   \n",
            "18  [upset, price, thought, embroidered, print, op...   \n",
            "19  [pullover, styling, side, zipper, purchased, k...   \n",
            "\n",
            "                                       stemmed_tokens  \\\n",
            "0   [high, hope, want, work, initi, petit, usual, ...   \n",
            "1    [jumpsuit, fun, flirti, fabul, time, compliment]   \n",
            "2   [shirt, due, adjust, front, tie, length, leg, ...   \n",
            "3   [traci, rees, dress, petit, feet, tall, brand,...   \n",
            "4   [basket, hte, person, store, pick, teh, pale, ...   \n",
            "5   [carbon, store, pick, ton, stuff, pair, skirt,...   \n",
            "6   [xs, run, snug, bust, feminin, usual, retail, ...   \n",
            "7   [lb, petit, make, length, long, typic, xs, reg...   \n",
            "8   [run, esp, zipper, area, run, sp, typic, fit, ...   \n",
            "9   [find, review, written, savvi, shopper, past, ...   \n",
            "10  [black, xs, larkspur, midi, bother, line, skir...   \n",
            "11  [choic, holiday, gather, length, knee, conserv...   \n",
            "12  [packag, want, badli, put, hour-glass, figur, ...   \n",
            "13  [materi, leg, open, larg, length, hit, ankl, l...   \n",
            "14  [chanc, blous, glad, crazi, blous, photograph,...   \n",
            "15  [super, cozi, coat, work, cold, dri, day, good...   \n",
            "16  [feel, tull, year', eve, chest, form, fit, ste...   \n",
            "17  [product, petit, petit, regular, long, tailor,...   \n",
            "18  [upset, price, thought, embroid, print, open, ...   \n",
            "19  [pullov, style, side, zipper, purchas, knew, s...   \n",
            "\n",
            "                                    lemmatized_tokens  \n",
            "0   [high, hope, want, work, initially, petite, us...  \n",
            "1   [jumpsuit, fun, flirty, fabulous, time, compli...  \n",
            "2   [shirt, due, adjustable, front, tie, length, l...  \n",
            "3   [tracy, reese, dress, petite, foot, tall, bran...  \n",
            "4   [basket, hte, person, store, pick, teh, pale, ...  \n",
            "5   [carbon, store, pick, ton, stuff, pair, skirt,...  \n",
            "6   [x, run, snug, bust, feminine, usual, retailer...  \n",
            "7   [lbs, petite, make, length, long, typically, x...  \n",
            "8   [run, esp, zipper, area, run, sp, typically, f...  \n",
            "9   [find, review, write, savvy, shopper, past, pr...  \n",
            "10  [black, x, larkspur, midi, bother, line, skirt...  \n",
            "11  [choice, holiday, gathering, length, knee, con...  \n",
            "12  [package, want, badly, put, hour-glass, figure...  \n",
            "13  [material, leg, open, large, length, hit, ankl...  \n",
            "14  [chance, blouse, glad, crazy, blouse, photogra...  \n",
            "15  [super, cozy, coat, work, cold, dry, day, good...  \n",
            "16  [feel, tulle, year's, eve, chested, form, fitt...  \n",
            "17  [product, petite, petite, regular, long, tailo...  \n",
            "18  [upset, price, think, embroidered, print, open...  \n",
            "19  [pullover, style, side, zipper, purchase, knew...  \n"
          ]
        }
      ],
      "source": [
        "print(df[[\"tokens\", \"stemmed_tokens\", \"lemmatized_tokens\"]].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(f\"processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing done. Vocabulary saved to vocabulary.txt\n"
          ]
        }
      ],
      "source": [
        "# 9. Build a vocabulary of the cleaned/processed reviews, and save it in a txt file \n",
        "all_tokens = [token for tokens in df[\"lemmatized_tokens\"] for token in tokens]\n",
        "vocabulary = sorted(set(all_tokens))\n",
        "vocab_dict = {word: i for i, word in enumerate(vocabulary)}\n",
        "\n",
        "# Save to file\n",
        "with open(\"vocabulary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for word, index in vocab_dict.items():\n",
        "        f.write(f\"{word}:{index}\\n\")\n",
        "\n",
        "print(\"Preprocessing done. Vocabulary saved to vocabulary.txt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
